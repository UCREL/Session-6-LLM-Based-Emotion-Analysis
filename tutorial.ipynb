{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UCREL/Session-6-LLM-Based-Emotion-Analysis/blob/main/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhrm-cinvBPZ"
      },
      "source": [
        "![](https://github.com/UCREL/Session-6-LLM-Based-Emotion-Analysis/blob/main/banner_llm4emotions_summer_school.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfrP_vfnfBe6"
      },
      "source": [
        "# **Introduction**\n",
        "With the advent the transformer based of large language models (LLMs) such as BERT, LLAMA, Gemini etc., the NLP community has tapped into these models for developing new techniques and methodologies for a wide range of NLP tasks. One key NLP task that can benefit from such resources is the Emotion Analysis, which is a highly challenging NLP task.  \n",
        "\n",
        "In this tutorial, we will learn how to:\n",
        "1. **Apply LLMs to emotion classification tasks**\n",
        "2. **Evaluate the performance of different models**\n",
        "3. **Fine-tune a model to perform better on specific classification tasks**\n",
        "\n",
        "To achieve the objectives above, we will follow the steps in the following sections:\n",
        "\n",
        "- [**Section 1: Preamble**](#preamble) - download tutorial materials and set path to working folder.\n",
        "\n",
        "- [**Section 2: Emotion Dataset Analysis**](#dataset-analysis) - load and analyse example emotion dataset.\n",
        "\n",
        "- [**Section 3: Emotion Classification**](#classification) - perform emotion classification with existing models.\n",
        "\n",
        "- [**Section 4: Model Evaluation**](#evaluation) - evaluate model performances on the dataset.\n",
        "\n",
        "- [**Section 5: Guide to Model Fine-tuning**](#fine-tuning) - a quick guide to fine-tuning an emotion LLM.\n",
        "\n",
        "\n",
        "<!--\n",
        "These content will be pushed to the relevant sections:\n",
        "\n",
        "tune three LLMs including BERT, RoBERTa, T5 and use them to classify emotion of some social media messages.\n",
        "\n",
        "Sample training and testing data will be provided which derive from publicly available GoEmotion corpus, and we will test classifying text using two emotion classification schemes: GoEmotion Scheme (27 emotion categories) and Ekman‚Äôs scheme (6 categories). The GoEmotion emotion categories can be mapped into Ekman‚Äôs categories.\n",
        "\n",
        "This tutorial will guide you on how to tune LLMs for emotion classification based on the two emotion schemes. To tune LLMs, we need to consider the charecteristics of each LLMs. For BERT and RoBERTa, they are similar which we need to connect them to the classification layer. On the other, T5 can generate text meaning we can ask the model directly by giving it an questions. Therefore, we do not need to create a classification layer for T5.  \n",
        "\n",
        "There are three mains step for tuning LLMs. The first step involves preparing data and setingup datamodule for tuning process. The second step is about creating tuning process. The final step is to review the tuning process by visualising tuning stats, then save the model. We break down these three step as follows:  \n",
        "\n",
        "\n",
        "\n",
        "1. Preparing data  \n",
        "1.1 Load data from files  \n",
        "1.2 Setup datamodule  \n",
        "2. Tuning process   \n",
        "2.1 Setup tuning process    \n",
        "2.2 Setup parameters and load model/tokeniser  \n",
        "2.3 Tune and test the model  \n",
        "3. Review tuning stat    \n",
        "3.1 Visualise tuning stat  \n",
        "3.2 Save the model\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KC2atDJaYoj"
      },
      "source": [
        "<a name=\"preamble\"></a>\n",
        "# **Section 1: Preamble**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPx92G2yULRZ"
      },
      "source": [
        "## Downloading materials\n",
        "To start, you need to download the materials required for this tutorial into our Colab space. These include the datasets and the python scripts required to perform other tasks.\n",
        "\n",
        "Let's walk you through the process with the following exercise...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUEmFWGk2k2Z"
      },
      "source": [
        "### **Exercise: üèãÔ∏è**\n",
        "Copy and paste these two lines of code to download materials from this session's [GitHub repo](https://github.com/UCREL/Session-6-LLM-Based-Emotion-Analysis/blob/main/tutorial.ipynb) and then change into our working directory `Session-6-LLM-Based-Emotion-Analysis`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dEplEtm3thQ"
      },
      "source": [
        "#### **1. Clone the repository:**\n",
        "```python\n",
        "!git clone https://github.com/UCREL/Session-6-LLM-Based-Emotion-Analysis.git\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoVECo_9iRbm"
      },
      "outputs": [],
      "source": [
        "# @title ##### üö¥‚Äç‚ôÇÔ∏è Clone the repository [Copy the code above and paste below üëá]:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuPqybZ53Ogn"
      },
      "source": [
        "#### **2. Change into the working directory:**\n",
        "```python\n",
        "%cd Session-6-LLM-Based-Emotion-Analysis\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7gOTu3c5M-7"
      },
      "outputs": [],
      "source": [
        "# @title ##### üö¥‚Äç‚ôÇÔ∏è Change into the working directory [Copy the code above and paste below üëá]:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1_I3pSK5IdH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycUiR2cnA-Ob"
      },
      "source": [
        "<a name=\"dataset-analysis\"></a>\n",
        "# **Section 2: Analyse Emotion Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35pbVj7N7NTt"
      },
      "source": [
        "Now, that we have everythin we need where we want them, let's begin by defining the function we need to read our data stored in the csv files and analyse them.\n",
        "\n",
        "We will use Python's `pandas` and `matplotlib`  for reading and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "acew71KyM5fE"
      },
      "outputs": [],
      "source": [
        "# @title ###### **Define functions**\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def load_dataset():\n",
        "  train = pd.read_csv(\"./sample_data/train.csv\")\n",
        "  val = pd.read_csv(\"./sample_data/val.csv\")\n",
        "  test = pd.read_csv(\"./sample_data/test.csv\")\n",
        "  return {'train': train, 'val': val, 'test': test}\n",
        "\n",
        "def plot_data_distribution(df, ax, xlabel=None, ylabel=None, category='ekman_label', kind='bar'):\n",
        "  df.groupby(category).size().plot(\n",
        "      kind=kind, color=sns.palettes.mpl_palette('Dark2'), ax=ax,\n",
        "      xlabel=xlabel, ylabel=ylabel, figsize=(15, 5))\n",
        "  ax.spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_pYYeMRp7ya",
        "outputId": "682b6f69-fc4d-4681-eba3-371fc4bd1a97"
      },
      "outputs": [],
      "source": [
        "# @title ##### **Loading and Analysing Emotion Data**\n",
        "dataset = load_dataset()\n",
        "combined_dataset = pd.concat([dataset['train'], dataset['val'], dataset['test']])\n",
        "\n",
        "print(f\"{'Training data':>16}: {len(dataset['train'])}\\n{'Validation data':>16}: {len(dataset['val'])} \\\n",
        "      \\n{'Testing data':>16}: {len(dataset['test'])}\\n{'Combined dataset':>16}: {len(combined_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xhaya6Ukure"
      },
      "source": [
        "There are 7 Ekman and 28 Go-Emotion Categories respectively. The labels and the indexes are shown below:\n",
        "\n",
        "Type | Categories\n",
        "--- | ---\n",
        "**Ekman (7 labels)** | 0: 'anger', 1: 'disgust', 2: 'fear', 3: 'joy', 4: 'neutral', 5: 'sadness', 6: 'surprise'\n",
        "**GoEmotion Labels (28 labels)** | 0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', <br>10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love',<br> 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Oyv1J5AWuAn4",
        "outputId": "2e4849b8-913c-462d-ffa3-a6f8179d3554"
      },
      "outputs": [],
      "source": [
        "# @title ##### **Let's see what our data looks like...** <br> The code below shows the top 100 rows. Adjust the value as you wish to see more (or less)...\n",
        "combined_dataset[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "gu22hXLhJ8iU",
        "outputId": "7aef97e4-d34b-4362-b27f-3f5f0625b149"
      },
      "outputs": [],
      "source": [
        "plot_data_distribution(df=combined_dataset, ax=plt.gca(), ylabel='No of instances', xlabel='Go-Emotion Categories', category='go_label', kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyQ-kpVX8-Qr"
      },
      "outputs": [],
      "source": [
        "# plot_data_distribution(df=combined_dataset, ax=plt.gca(), xlabel='dataset', category='go_label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "5OxVV0-atl1r",
        "outputId": "2b9c182a-92ef-476d-d962-3ed875afc1b1"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Ekman Labels Distribution')\n",
        "plot_data_distribution(datadf=traindf, ax=axes[0], xlabel='train data')\n",
        "plot_data_distribution(datadf=valdf,   ax=axes[1], xlabel='validation data')\n",
        "plot_data_distribution(datadf=testdf,  ax=axes[2], xlabel='test data')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "BrGQFX0YuXcj",
        "outputId": "ba6bcc0e-399d-4f46-e26e-b1c7f7377d37"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "testdf.groupby('ekman_label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpQNEWeTULRZ"
      },
      "source": [
        "<a name=\"classification\"></a>\n",
        "# **Section 3: Emotion Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_LHnlULULRb"
      },
      "source": [
        "\n",
        "This section will show you how to classify emotion using BERT and T5 available at <a herf=\"https://huggingface.co/\">Hugging Face</a>. The text classification involves two main process which are text pre-processing and text classification. For text pre-processing, it is a process where we transform a text into suitable format, such as from text to vector. Text tokenization is one of the transformation method which maps each word in the text to its word id creating a text representative vector. After the pre-processing, we pass the text vector to emotion classifier and wait for result.  \n",
        "\n",
        "The following sub-sections will show you how to tokenize text and create emotion classifiers based on BERT and T5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install and import required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pytorch_lightning\n",
        "# !pip install csv-logger\n",
        "# !pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BERT Emotion Classifier\n",
        "\n",
        "In this tutorial, we illustrate the implementation based on torch and pytorch-lightning libraries.  \n",
        "\n",
        "As explained earlier, we need to perform text tokeniation and create classifier. However, before that, let's create a Python class storing our data. We will use torch Dataset for implementation. The Dataset can be used to store our texts and their labels. Moreover, the stored texts and labels can be easily accessed using indexing. The code below shows and example of BERTDataset class which stores all the data.  \n",
        "\n",
        "```python\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, df, datacolumn, labelcolumn):\n",
        "        self.data = df\n",
        "        self.texts = self.data[datacolumn].tolist()\n",
        "        self.labels = self.data[labelcolumn].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.texts))\n",
        "```\n",
        "\n",
        "The BERTDataset stores texts and their labels in self.texts and self.labels respectively. The texts and labels are from the data in the previous section which are in pandas Dataframe. The datacolumn and labelcolumn indicate which columns texts and labels are in.    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To access our data by index, we can add __getitem__ function to the Dataset class. The function will return text and label of the givin index. However, as we need to tokenized texts, we return a tokenized text instead. The __getitem__ function is shown below.\n",
        "\n",
        "```python\n",
        "def __getitem__(self,idx):\n",
        "        # get text and label by index\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        # tokenization\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "                                                text,\n",
        "                                                max_length = self.max_length,\n",
        "                                                add_special_tokens = True,\n",
        "                                                padding = 'max_length',\n",
        "                                                truncation = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                return_tensors = 'pt',)\n",
        "        # return tokenized text and its label\n",
        "        return {'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'label': torch.tensor(label),\n",
        "                }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we tokenize text in the __getitem__ function, we will need to include tokenizer to our class as well. Thus, we modify BERTDataset class a litle bit and put everything together. The finished BERTDataset class is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mlF1hoIXULRb",
        "outputId": "dee5afaf-8238-4d58-b9f8-2c1987c09849"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length, datacolumn, labelcolumn):\n",
        "        self.data = df\n",
        "        self.texts = self.data[datacolumn].tolist()\n",
        "        self.labels = self.data[labelcolumn].tolist()\n",
        "        # tokenizer and necessary parameter\n",
        "        self.tokenizer = tokenizer \n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.texts))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "                                                text,\n",
        "                                                max_length = self.max_length,\n",
        "                                                add_special_tokens = True,\n",
        "                                                padding = 'max_length',\n",
        "                                                truncation = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                return_tensors = 'pt',)\n",
        "\n",
        "        return {'input_ids': encoding['input_ids'].flatten(),\n",
        "                'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'label': torch.tensor(label),\n",
        "                }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, our dataset and text tokenization are ready. Let's start creating BERT emotion classifier. First, we need to create a classification layer which is connected to BERT. This is because BERT itself cannot perform classification taks. However, BERT can understand English text and encode the text into a vector. Next, we will pass the encoded text vector to the classification layer for emotion classification.   \n",
        "\n",
        "For classification layer, we will create a simple neuron network comprise of linear layer, dropout layer, and output layer. We will use pytorch-lightnight for implementation as shown below.  \n",
        "\n",
        "```python\n",
        "class BERTClassifier(pl.LightningModule):\n",
        "    def __init__(self, model, num_class, emotion_index):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.num_class = num_class\n",
        "        self.emotion_index = emotion_index\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, self.num_class) # output layer\n",
        "\n",
        "```\n",
        "\n",
        "The above code shows the implementation of our BERTclassifier. We define necessary elements. Next. let's setup the forward function which will connect all theses layers and classify emotion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooler = outputs[0][:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        logits = self.classifier(pooler)\n",
        "\n",
        "        return logits\n",
        "```\n",
        "\n",
        "The forward function shows the sequence of layers explained previously. The function return the result of the last layer which are classification output. Next, we will create a function for emotion classification which connect BERTDataset to BERTClassifier. \n",
        "\n",
        "```python\n",
        "def emo_classification(self, dataset):\n",
        "        predictions = []\n",
        "        for _d in dataset:\n",
        "            logits = self(_d['input_ids'].unsqueeze(0), _d['attention_mask'].unsqueeze(0))\n",
        "            _, pred = torch.max(logits, dim = 1)\n",
        "            index= pred.numpy()[0]\n",
        "            predictions.append(self.emotion_index[index])\n",
        "        return predictions\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The emotion_classification will interate over the dataset and classify emotion for each text. As we already tokenized the text, this function will access the tokenized text then pass it to forward function. Then we store the classifation results are return them. The below code cell show the full class of BERTClassifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BERTClassifier(pl.LightningModule):\n",
        "    def __init__(self, model, num_class, emotion_index):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.num_class = num_class\n",
        "        self.emotion_index = emotion_index\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, self.num_class)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooler = outputs[0][:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        logits = self.classifier(pooler)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def emo_classification(self, dataset):\n",
        "        predictions = []\n",
        "        for _d in dataset:\n",
        "            logits = self(_d['input_ids'].unsqueeze(0), _d['attention_mask'].unsqueeze(0))\n",
        "            _, pred = torch.max(logits, dim = 1)\n",
        "            index= pred.numpy()[0]\n",
        "            predictions.append(self.emotion_index[index])\n",
        "        return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-ATLFsULRc"
      },
      "source": [
        "With classifier and dataset, let's setup parameter and perform the classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters\n",
        "CLASSES = 7\n",
        "DATACOLUMN = 'text'\n",
        "LABLECOLUMN = 'ekman_index'\n",
        "EMOTION_INDEX = {0: 'anger', \n",
        "                 1: 'disgust', \n",
        "                 2: 'fear', \n",
        "                 3: 'joy', \n",
        "                 4: 'neutral', \n",
        "                 5: 'sadness', \n",
        "                 6: 'surprise'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download BERT model and init BERT classifier\n",
        "\n",
        "BERT_MODEL = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "BERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "BERTcls = BERTClassifier(\n",
        "    model=BERT_MODEL,\n",
        "    num_class=CLASSES,\n",
        "    emotion_index = EMOTION_INDEX)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get data ready\n",
        "# we sample 10 instances from dataset['test']\n",
        "# you can try the whole data by replacing data with dataset['test']\n",
        "\n",
        "data = dataset['test'].sample(n=10, random_state=1)\n",
        "\n",
        "Bertdata = BERTDataset(df = data, \n",
        "                       tokenizer = BERT_TOKENIZER, \n",
        "                       max_length = BERT_TOKENIZER.model_max_length,\n",
        "                       datacolumn = DATACOLUMN, \n",
        "                       labelcolumn = LABLECOLUMN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# classification\n",
        "bert_pred = BERTcls.emo_classification(Bertdata)\n",
        "bert_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## T5 Emotion Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We showed how to use BERT for emotion classification. For T5, the process is similar to that of BERT which we need to create Dataset and T5 classifier. Howver, the difference is that T5 can generate text on its own which we do not need to create a classification layer. Therefore, we can use T5 to directly generate emotion.  \n",
        "\n",
        "For text generation, we need to be careful of the length of text generation because we do not want the classifier to over generate. In our case, we want the classifier to generate one emotion categories not a full sentences. Therefore, we need to limit the length of generated text. To do that, let's first observe the length of tokenized emotion categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load T5 and tokenizer \n",
        "\n",
        "T5_MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-small\", return_dict=True)\n",
        "T5_TOKENIZER = T5Tokenizer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# try tokenize emotion categories\n",
        "DATACOLUMN = 'text'\n",
        "LABLECOLUMN = 'ekman_label'\n",
        "\n",
        "generated_output_length = [(e, len(T5_TOKENIZER.encode(e)), T5_TOKENIZER.encode(e)) for e in dataset['train'][LABLECOLUMN].unique()]\n",
        "output_length_df = pd.DataFrame(generated_output_length, columns=['Emotion', 'No. tokens', 'Token ids'])\n",
        "output_length_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above output shows that the maximum token lengths is 2. This means that we will limit the length of generated text to 2. Next, let's defined our dataset and T5 classifier.  \n",
        "\n",
        "For dataset, we will use the same class for implementation 'Dataset'. Unlike BERT, before text tokenization, we need to add instruction text as a prefix to tell T5 what to do. In our example, we add 'emotion classification:' before the text. Then tokenize the text as usual. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class T5Dataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_maxlength, label_maxlength, datacolumn, labelcolumn):\n",
        "        self.data = df\n",
        "        self.texts = self.data[datacolumn].tolist()\n",
        "        self.labels = self.data[labelcolumn].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_maxlength = text_maxlength\n",
        "        self.label_maxlength = label_maxlength\n",
        "        \n",
        "    def __len__(self):\n",
        "        return(len(self.texts))\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        # T5 transformers performs different tasks by prepending the particular prefix to the input text.\n",
        "        # In order to avoid dtype mismatch, as T5 is text-to-text transformer, the datatype must be string\n",
        "        text = \"emotion classification:\" + str(self.texts[idx])\n",
        "        label = str(self.labels[idx]).lower()\n",
        "        text_tokenizer = self.tokenizer(text, max_length=self.text_maxlength, padding=\"max_length\")\n",
        "        label_tokenizer = self.tokenizer(label, max_length=self.label_maxlength, padding=\"max_length\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(text_tokenizer[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(text_tokenizer[\"attention_mask\"], dtype=torch.long),\n",
        "            \"label_ids\": torch.tensor(label_tokenizer[\"input_ids\"], dtype=torch.long),\n",
        "            \"label_mask\": torch.tensor(label_tokenizer[\"attention_mask\"], dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For classifier, T5 comes with generate function which will take tokenized text as input and generate output directly. This means we do not need to create a forward function as we did with BERT. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class T5Classifier(pl.LightningModule):\n",
        "    def __init__(self, model, tokenizer, generated_max_length):\n",
        "        super(T5Classifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.generated_max_length = generated_max_length\n",
        "    \n",
        "    def emo_classification(self,dataset):\n",
        "        predictions = []\n",
        "        for _d in dataset:\n",
        "            pred = self.model.generate(input_ids=_d['input_ids'].unsqueeze(0),\n",
        "                                         attention_mask=_d['attention_mask'].unsqueeze(0),\n",
        "                                         max_length=self.generated_max_length)\n",
        "            _pred = self.tokenizer.decode(pred[0],skip_special_tokens=True)\n",
        "            predictions.append(_pred)\n",
        "        return predictions\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classification concept is similar to that of BERT. Firstly, we interate over the dataset and generate emotion for each text. The generated text length is limited to 2. Then, we store all the prediction and return them.  \n",
        "\n",
        "Now, the classifier and dataset are ready. Let's try classify emotion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Output max length\n",
        "OUTPUTLENGTH = output_length_df['No. tokens'].max()\n",
        "\n",
        "T5cls = T5Classifier(\n",
        "    model=T5_MODEL,\n",
        "    tokenizer=T5_TOKENIZER,\n",
        "    generated_max_length=2)\n",
        "\n",
        "t5data = T5Dataset(df = data, \n",
        "                       tokenizer = T5_TOKENIZER, \n",
        "                       text_maxlength = T5_TOKENIZER.model_max_length,\n",
        "                       label_maxlength = 2,\n",
        "                       datacolumn = DATACOLUMN, \n",
        "                       labelcolumn = LABLECOLUMN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# classification result\n",
        "t5_pred = T5cls.emo_classification(t5data)\n",
        "t5_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To this point, we illustrated how to classify emotion using BERT and T5. Next section will show you how to evaluate performance of the two classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"evaluation\"></a>\n",
        "# **Section 4: Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will evaluate emotion classification performance of two classifiers, BERT and T5. We will use accuracy to compare the performace of the two classifiers. First let's defined accuracy function. The accuracy is the ratio of number of correctly predicted texts and total number of texts. The accuracy function is defined below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# accuracy function\n",
        "def accuracy(actual_label,pred):\n",
        "    return sum([1 if a == p else 0 for a,p in zip(actual_label,pred)])/len(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's look at our classification results and the sampled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.loc[:, ['text','ekman_label']]\n",
        "data['bert'] = bert_pred\n",
        "data['t5'] = t5_pred\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's calculate accuracy of each classifier and compare them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "performance = {} \n",
        "performance['bert'] = [accuracy(data.ekman_label.tolist(), data.bert.to_list())]\n",
        "performance['t5'] = [accuracy(data.ekman_label.tolist(), data.t5.to_list())]\n",
        "\n",
        "perm = pd.DataFrame(performance)\n",
        "perm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perm.plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As can be seen, the performance of the two classifers is quit low. In the next section, we will show you how to improve the performance of the two classifiers by tuning them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"fine-tuning\"></a>\n",
        "# **Section 5: Guide to Model Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To improve the perofrmance of our classifier, we need to tune the classifier which will help them adapt to our emotion classification task. The tuning process is a supervised learning where the classifiers learn how to classify emotion based on given examples (training data). Each round of training is called epoch and for each epoch, we divine data into batches. The classifiers will learnt at the end of each batch by updating its weights. \n",
        "\n",
        "Therefore, we will create a training loop providing texts and their labels for the classifiers to learn. During the process, we also provide a set of data which will be used for validating our classifiers at the end of each round of leanring.  \n",
        "\n",
        "For implementation, we will use the defined BERT and T5 classes earlier. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BERT Classifier tuning  \n",
        "\n",
        "Before we drive into training and validating, we first need to create a method for divining our data into batches for training. It can also be used to provind data for validating and testing. We will use DataModule of pytorch-lightning for the implementataion. The DataModule stores train, validation, and test dataset and facilitate batch process for tuning process. The code below show the DataModule class. \n",
        "\n",
        "```python\n",
        "class BERTDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, traindf, valdf, testdf, batch_size, tokenizer, max_length, datacolumn, labelcolumn):\n",
        "        super().__init__()\n",
        "        # dataset\n",
        "        self.traindf = traindf\n",
        "        self.valdf = valdf\n",
        "        self.testdf = testdf\n",
        "        self.datacolumn = datacolumn\n",
        "        self.labelcolumn = labelcolumn\n",
        "        # parameters \n",
        "        self.batch_size = batch_size\n",
        "        self.max_length = max_length\n",
        "        # tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = BERTDataset( self.traindf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "        self.val_dataset = BERTDataset( self.valdf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "        self.test_dataset = BERTDataset( self.testdf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "        \n",
        "```\n",
        "\n",
        "In setup function, the BERTDataModule creates BERTDataset objects of train, validate, and test dataset, and stores them in its class. Next, we will add functions to provide access to each of the BERTDataset objects as shown below.\n",
        "\n",
        "```python\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader( self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader( self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader( self.test_dataset, batch_size=self.batch_size)\n",
        "```\n",
        "\n",
        "The above functions will be called during training, validating, and testing steps. These functions return a DataLoader object with batch_size parameters. The final look of our class is shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJJGum9AULRd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BERTDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, traindf, valdf, testdf, batch_size, tokenizer, max_length, datacolumn, labelcolumn):\n",
        "        super().__init__()\n",
        "        # dataset\n",
        "        self.traindf = traindf\n",
        "        self.valdf = valdf\n",
        "        self.testdf = testdf\n",
        "        self.datacolumn = datacolumn\n",
        "        self.labelcolumn = labelcolumn\n",
        "        # parameters \n",
        "        self.batch_size = batch_size\n",
        "        self.max_length = max_length\n",
        "        # tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = BERTDataset( self.traindf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "        self.val_dataset = BERTDataset( self.valdf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "        self.test_dataset = BERTDataset( self.testdf, self.tokenizer, self.max_length, self.datacolumn, self.labelcolumn)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader( self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader( self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader( self.test_dataset, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfGgMlf9ULRe"
      },
      "source": [
        "We have setup DataModule for tuning. Next, let's modify our BERTClassifier. We need to add three functions for training, validating, and testing.  \n",
        "\n",
        "```python\n",
        "def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "\n",
        "        logits = self(input_ids, attention_mask)\n",
        "        _, preds = torch.max(logits, dim = 1)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "        self.log('train_loss', loss, on_epoch=True)\n",
        "        self.log('train_acc',(preds == labels).sum() / len(labels), on_epoch=True)\n",
        "        return loss\n",
        "```\n",
        "\n",
        "The training_step takes batch data provided by the train_dataloader of BERTDataModule. For each batch, the input will be pass to forward function. Then we calculate loss and return it. We also keep tracking loss and accuracy during the training.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As for validating_step, the code is similar to that of training_step. However, during validation, the function will call val_dataloader of the BERTDataModule for validation dataset. The rest of the process is the same. \n",
        "\n",
        "```python\n",
        "def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"label\"]\n",
        "\n",
        "    logits = self(input_ids, attention_mask)\n",
        "    _, preds = torch.max(logits, dim = 1)\n",
        "    loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "    self.log('val_loss', loss)\n",
        "    self.log('val_acc', (preds == labels).sum() / len(labels))\n",
        "    return loss\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In test_step, we do not need to return loss and we want to test our classifier based on the test dataset. Still, the process is similar the the other two steps.\n",
        "\n",
        "```python\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "        logits = self(input_ids=input_ids,\n",
        "                      attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        _, preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', (preds == labels).sum() / len(labels))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have defined all functions. The last step is to define an optimizer used for updating our classifier. The optimizer needs parameters such as learning rate, number of training steps, and number of warmup steps. These parameters will be setup during classifier init. In our example, we use Adam optimizer as shown below.\n",
        "\n",
        "```python\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=0,\n",
        "                num_training_steps=self.epoch*self.train_size)\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "```\n",
        "\n",
        "The modified BERTClassifier is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHVTBdszULRe"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(pl.LightningModule):\n",
        "    def __init__(self, model, num_class, learning_rate, epoch, train_size):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.num_class = num_class\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epoch = epoch\n",
        "        self.train_size = train_size\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, self.num_class)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        pooler = outputs[0][:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        logits = self.classifier(pooler)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "\n",
        "        logits = self(input_ids, attention_mask)\n",
        "        _, preds = torch.max(logits, dim = 1)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "        self.log('train_loss', loss, on_epoch=True)\n",
        "        self.log('train_acc',(preds == labels).sum() / len(labels), on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "\n",
        "        logits = self(input_ids, attention_mask)\n",
        "        _, preds = torch.max(logits, dim = 1)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', (preds == labels).sum() / len(labels))\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "        logits = self(input_ids=input_ids,\n",
        "                      attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        _, preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', (preds == labels).sum() / len(labels))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=0,\n",
        "                num_training_steps=self.epoch*self.train_size)\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezY36nXiULRe"
      },
      "source": [
        "Next, let's setup parameter, datamodule, and classifier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters \n",
        "EPOCH = 2 # two rounds of training\n",
        "CLASSES = 7 # emotion categories \n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_SIZE = len(dataset['train'])\n",
        "MAX_LENGTH = BERT_TOKENIZER.model_max_length #512\n",
        "\n",
        "DATACOLUMN = 'text'\n",
        "BERTLABLECOLUMN = 'ekman_index'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datamodule\n",
        "BERTdata_module = BERTDataModule(traindf=dataset['train'],\n",
        "                               valdf=dataset['val'],\n",
        "                               testdf=dataset['test'],\n",
        "                               tokenizer=BERT_TOKENIZER,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               max_length=MAX_LENGTH,\n",
        "                               datacolumn=DATACOLUMN,\n",
        "                               labelcolumn=BERTLABLECOLUMN)\n",
        "BERTdata_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# classifier\n",
        "BERTcls = BERTClassifier(\n",
        "    model=BERT_MODEL,\n",
        "    num_class=CLASSES,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    epoch=EPOCH,\n",
        "    train_size=TRAIN_SIZE)\n",
        "\n",
        "# unblock to print classifier structure\n",
        "# BERTcls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create a log file to record tuning performance and losses using CSVLogger. For tuning, we will use pytorch trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup save path for log file\n",
        "logger = CSVLogger(\"./logs\", name='BERT_exp', version=1)\n",
        "\n",
        "# using pytorch trainer for tuning\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    max_epochs=EPOCH,\n",
        "    precision=\"16-mixed\",\n",
        "    logger=logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before tuning, let's first test the classifier. Previously, we only test based on a small samples of our test dataset. Now, we will test the classifier on the whole test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.test(BERTcls, BERTdata_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the result above. It is quit low. Let's strat tuning then test it again. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.fit(BERTcls, BERTdata_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test again\n",
        "trainer.test(BERTcls, BERTdata_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BstvVuSlULRg"
      },
      "source": [
        "We can see the improvement of the classifier's performance. Next, let's review tuning/testing loss and performance. The information is stored in the log file in './logs/BERT_exp' directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yVLz_qIULRh",
        "outputId": "e33eaa7e-aa0b-4cb7-eaa0-a4a67fc15c11"
      },
      "outputs": [],
      "source": [
        "def GetTuningStats(path):\n",
        "    metrices = pd.read_csv(path)\n",
        "    training_metric = metrices[['train_acc_epoch','train_loss_epoch']].dropna().reset_index(drop=True)\n",
        "    validate_metric = metrices[['val_acc','val_loss']].dropna().reset_index(drop=True)\n",
        "    testing_metric = metrices[['test_acc']].dropna().reset_index(drop=True)\n",
        "    merge_matrices = pd.merge(training_metric,validate_metric, left_index=True, right_index=True)\n",
        "    return testing_metric, merge_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BERT_performance, BERT_losses = GetTuningStats('./logs/BERT_exp/version_1/metrics.csv')\n",
        "BERT_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The improvement is obvious!!! Let's plot the losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqcg3Ve6ULRj",
        "outputId": "6b9efa74-66eb-4629-9f85-6c156c3898f3"
      },
      "outputs": [],
      "source": [
        "# losses of each epoch\n",
        "BERT_losses[['train_loss_epoch','val_loss']].plot()\n",
        "# accuracy of each epoch\n",
        "BERT_losses[['train_acc_epoch','val_acc']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The below code show how to save and load the classifier for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyLOy9PtULRm"
      },
      "outputs": [],
      "source": [
        "# # saving\n",
        "# torch.save(BERTcls.state_dict(), './bert.pt')\n",
        "# # loading\n",
        "# saved_model = BERTClassifier(\n",
        "#     model=BERT_MODEL,\n",
        "#     num_class=CLASSES,\n",
        "#     learning_rate=LEARNING_RATE,\n",
        "#     epoch=EPOCH,\n",
        "#     train_size=TRAIN_SIZE)\n",
        "# saved_model.load_state_dict(torch.load('./bert.pt'))\n",
        "# saved_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFIb8l8wULRt"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDlTnRKULRt"
      },
      "source": [
        "## T5 tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nwfwa9mULRu"
      },
      "source": [
        "Tuning process of T5 is similar to BERT. We need to create DataModule and add training, testing, validating steps to T5Classifier. We also add optimizer to the classifier.  \n",
        "\n",
        "The code below shows T5DatModule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGCLepfzULR5"
      },
      "outputs": [],
      "source": [
        "class T5DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, traindf, valdf, testdf, batch_size, tokenizer, text_maxlength, label_maxlength, datacolumn, labelcolumn):\n",
        "        super().__init__()\n",
        "        # dataset \n",
        "        self.datacolumn = datacolumn\n",
        "        self.labelcolumn = labelcolumn\n",
        "        self.traindf = traindf\n",
        "        self.valdf = valdf\n",
        "        self.testdf = testdf\n",
        "        # parameters\n",
        "        self.batch_size = batch_size\n",
        "        self.text_maxlength = text_maxlength\n",
        "        self.label_maxlength = label_maxlength\n",
        "        # tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = T5Dataset( self.traindf, self.tokenizer, self.text_maxlength, self.label_maxlength, self.datacolumn, self.labelcolumn)\n",
        "        self.val_dataset = T5Dataset( self.valdf, self.tokenizer, self.text_maxlength, self.label_maxlength, self.datacolumn, self.labelcolumn)\n",
        "        self.test_dataset = T5Dataset( self.testdf, self.tokenizer, self.text_maxlength, self.label_maxlength, self.datacolumn, self.labelcolumn)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader( self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader( self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader( self.test_dataset, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T5DataModule is similar to that of BERT. The differences are that it stores T5Dataset which needs different parameters.  \n",
        "\n",
        "In the previous section, we do not need forward function because we only generate emotions. However, for tuning, we need to define forward function to return loss.\n",
        "\n",
        "```python\n",
        "    def forward(self, input_ids, attention_mask, labels=None, decoder_attention_mask=None):\n",
        "        outputs = self.model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels,\n",
        "                        decoder_attention_mask=decoder_attention_mask)\n",
        "        return outputs.loss, outputs.logits\n",
        "```\n",
        "\n",
        "The forward function will pass a batch input through the model (T5). Then, it will return loss.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the forward function return loss, the training_step function will directly return output from the forward function. In the function, we also record loss and training performance. For training performance, we use model's generate function to generate then compare the generated text with label.\n",
        "\n",
        "```python\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label_ids\"]\n",
        "        decoder_attention_mask = batch[\"label_mask\"]\n",
        "\n",
        "        loss, output = self(input_ids, attention_mask, labels, decoder_attention_mask)\n",
        "        pred = self.model.generate(input_ids=input_ids,\n",
        "                                     attention_mask=attention_mask,\n",
        "                                     max_length=self.generated_max_length)\n",
        "\n",
        "        self.log('train_acc', self.accuracy_score(output, labels), on_epoch=True)\n",
        "        self.log('train_loss', loss,  on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The accuracy evaluation fuction is defined below.  \n",
        "\n",
        "```python\n",
        "    def accuracy_score(self,preds,labels):\n",
        "        _preds = [self.tokenizer.decode(p,skip_special_tokens=True) for p in preds]\n",
        "        _labels = [self.tokenizer.decode(l,skip_special_tokens=True) for l in labels]\n",
        "        return sum([1 if _p==_l else 0 for _p ,_l in zip(_preds,_labels)])/len(_labels)\n",
        "```\n",
        "\n",
        "We decode the generated text and label. Then we calculate and return the accuracy score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validating step is similar to the training step. For testing step, we use T5 to generate text and call accuracy_score function to evaluate the performance of the classifier. The optimizer used for T5 is similart to that of BERT's. Therefore, T5Classifier can be defined as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cflX6WtcULR5"
      },
      "outputs": [],
      "source": [
        "class T5Classifier(pl.LightningModule):\n",
        "    def __init__(self, model, tokenizer, epoch, train_size, generated_max_length, learning_rate):\n",
        "        super(T5Classifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.epoch = epoch\n",
        "        self.train_size = train_size\n",
        "        self.generated_max_length = generated_max_length\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None, decoder_attention_mask=None):\n",
        "        outputs = self.model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels,\n",
        "                        decoder_attention_mask=decoder_attention_mask)\n",
        "        return outputs.loss, outputs.logits\n",
        "\n",
        "    def accuracy_score(self,preds,labels):\n",
        "        _preds = [self.tokenizer.decode(p,skip_special_tokens=True) for p in preds]\n",
        "        _labels = [self.tokenizer.decode(l,skip_special_tokens=True) for l in labels]\n",
        "        return sum([1 if _p==_l else 0 for _p ,_l in zip(_preds,_labels)])/len(_labels)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label_ids\"]\n",
        "        decoder_attention_mask = batch[\"label_mask\"]\n",
        "\n",
        "        loss, output = self(input_ids, attention_mask, labels, decoder_attention_mask)\n",
        "        pred = self.model.generate(input_ids=input_ids,\n",
        "                                     attention_mask=attention_mask,\n",
        "                                     max_length=self.generated_max_length)\n",
        "\n",
        "        self.log('train_acc', self.accuracy_score(pred, labels), on_epoch=True)\n",
        "        self.log('train_loss', loss,  on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label_ids\"]\n",
        "        decoder_attention_mask = batch[\"label_mask\"]\n",
        "\n",
        "        loss, output = self(input_ids, attention_mask, labels, decoder_attention_mask)\n",
        "        \n",
        "        pred = self.model.generate(input_ids=input_ids,\n",
        "                                     attention_mask=attention_mask,\n",
        "                                     max_length=self.generated_max_length)\n",
        "\n",
        "        self.log('val_acc', self.accuracy_score(pred, labels))\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        output = self.model.generate(input_ids=input_ids,\n",
        "                                     attention_mask=attention_mask,\n",
        "                                     max_length=self.generated_max_length)\n",
        "        self.log('test_acc', self.accuracy_score(output, batch[\"label_ids\"]))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=0,\n",
        "                num_training_steps=self.epoch*self.train_size)\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's setup parameters, datamodule, and classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq7PaS4aULR6"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "EPOCH = 2\n",
        "BATCH_SIZE = 8\n",
        "LABEL_LENGTH = 2\n",
        "LEARNING_RATE = 2e-5\n",
        "MODEL_MAX_LENGTH = T5_TOKENIZER.model_max_length\n",
        "\n",
        "DATACOLUMN = 'text'\n",
        "T5LABELCOLUMN = 'ekman_label'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em5JMU5UULR6"
      },
      "outputs": [],
      "source": [
        "# datamodule\n",
        "T5data = T5DataModule(traindf = dataset['train'],\n",
        "                      valdf = dataset['val'],\n",
        "                      testdf = dataset['test'],\n",
        "                      batch_size = BATCH_SIZE,\n",
        "                      tokenizer = T5_TOKENIZER,\n",
        "                      text_maxlength = MODEL_MAX_LENGTH,\n",
        "                      label_maxlength = LABEL_LENGTH,\n",
        "                      datacolumn = DATACOLUMN,\n",
        "                      labelcolumn = T5LABELCOLUMN)\n",
        "T5data.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a0c5baed0e4c4adba24ad774f6e4d652",
            "a21d2975935446479c91bcc3a6ef9168",
            "904682eac5c646629fca7b308481cf31",
            "3321dba1b08f4bb88232a32d7482fc0b"
          ]
        },
        "id": "6bFSlPpQULR6",
        "outputId": "2e864907-2765-4207-9563-f2098a28c363"
      },
      "outputs": [],
      "source": [
        "# save directory\n",
        "logger = CSVLogger(\"./logs\", name='T5_ekman', version=1)\n",
        "\n",
        "# classifier\n",
        "T5cls = T5Classifier(model = T5_MODEL,\n",
        "                     tokenizer = T5_TOKENIZER,\n",
        "                     epoch = EPOCH,\n",
        "                     train_size = TRAIN_SIZE,\n",
        "                     generated_max_length = LABEL_LENGTH,\n",
        "                     learning_rate=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer for tuning\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    max_epochs=EPOCH,\n",
        "    precision=\"16-mixed\",\n",
        "    logger=logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's evaluate our classifier before tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.test(T5cls, T5data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.fit(T5cls, T5data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate again!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9ca5c4e2bb354056b6a326404dcb2371"
          ]
        },
        "id": "HDYLbP6tULR6",
        "outputId": "9d071671-64cd-4a7f-83dc-0b68de937a94"
      },
      "outputs": [],
      "source": [
        "trainer.test(T5cls, T5data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's review performance and losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXSBCpsEULR7",
        "outputId": "cc7defb2-cc85-480b-f9bc-c34da71418c4"
      },
      "outputs": [],
      "source": [
        "t5_performance , t5_losses = GetTuningStats('./logs/T5_ekman/version_1/metrics.csv')\n",
        "t5_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkJd1On8ULR7",
        "outputId": "2686b77b-2eee-4913-af07-9d2abb5c1a61"
      },
      "outputs": [],
      "source": [
        "t5_losses[['train_loss_epoch','val_loss']].plot()\n",
        "t5_losses[['train_acc_epoch','val_acc']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T5 classifier can also be saved as same as BERT classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LFZce3tULR7",
        "outputId": "4569ee55-a077-49fc-eacb-1d2ba5d643b6"
      },
      "outputs": [],
      "source": [
        "# # saving\n",
        "# torch.save(T5cls.state_dict(), './t5.pt')\n",
        "# # loading\n",
        "# saved_model = T5Classifier(model = T5_MODEL,\n",
        "                    #  tokenizer = T5_TOKENIZER,\n",
        "                    #  epoch = EPOCH,\n",
        "                    #  train_size = TRAIN_SIZE,\n",
        "                    #  generated_max_length = LABEL_LENGTH,\n",
        "                    #  learning_rate=LEARNING_RATE)\n",
        "# saved_model.load_state_dict(torch.load('./t5.pt'))\n",
        "# saved_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the performance of the two classifier before and after tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ow6vsoaqULR9"
      },
      "outputs": [],
      "source": [
        "performances = pd.concat([BERT_performance, t5_performance], axis=1)\n",
        "performances.columns = ['bert','t5']\n",
        "performances['status'] = ['before', 'after']\n",
        "performances.plot.bar(x='status')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "phdenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02ca9c20647b471796d82c92252a19c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a474ebed5384fb2a037857765d237ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b9a0f86573e4c5eaa1ef2a80f36a2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "101660bc543e4e4591dd936989261557": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134f3aed1cb9418d930792b58c2261e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f371d7946e44d7a1e3985b5cebb1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f80f5eeee941bda1b76d369b62be18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b3f86719ee34f6fbb28ad523e17738d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed4fbc9be8442ca9c494a29f44628f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab581f3b41a94744844299f83c80f296",
              "IPY_MODEL_3cd0383bfaa04e75a28968455e4fdc8c",
              "IPY_MODEL_ac9f86d77fe340568102011d7aa1b651"
            ],
            "layout": "IPY_MODEL_13f371d7946e44d7a1e3985b5cebb1b4"
          }
        },
        "20cd5f5a94834c2691550d1f2f2c4009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70110f0b6bcb45b594e5f11c48f13db8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3b7fdab9655f445ca9df09dc498fd05e",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "20f0695909eb4aa790db46465260d33b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e13ca4e87b43058c359753f8ba0387": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a728ed2b1c44422a8e45f25558ab6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2addf98dbfe6440ea3bd64882dd57426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eae35b776504ad69bf8600a51c87ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7fdab9655f445ca9df09dc498fd05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4a0346c8544aadb10f7d727506ccde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd0383bfaa04e75a28968455e4fdc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27e13ca4e87b43058c359753f8ba0387",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a728ed2b1c44422a8e45f25558ab6cb",
            "value": 570
          }
        },
        "4ab2ec8d20e44143a449c303c49ba6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b3f86719ee34f6fbb28ad523e17738d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16f80f5eeee941bda1b76d369b62be18",
            "value": 466062
          }
        },
        "5389991b4163470eb76c8c710706c190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95bc6c97d29e4e558f7efccacf8ba8c3",
              "IPY_MODEL_dcabd2bf5f2d45f19e7f49d976f41202",
              "IPY_MODEL_68421dd8ab5c4c66af1fc1e4cd5516f4"
            ],
            "layout": "IPY_MODEL_134f3aed1cb9418d930792b58c2261e2"
          }
        },
        "5d828c77f77a4bdeb88ae4f579562bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d1ac64ca834a4697667a534a546c47",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce7a9ec7d56349bb8a8d2d5ae1685177",
            "value": 48
          }
        },
        "68421dd8ab5c4c66af1fc1e4cd5516f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f0695909eb4aa790db46465260d33b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a474ebed5384fb2a037857765d237ea",
            "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá2.83MB/s]"
          }
        },
        "70110f0b6bcb45b594e5f11c48f13db8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7762ad851c2e4f85a8b02d5925d52175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7deae95c8b4c7fa0c47d71b0ffa8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcc6e8fc93349a4ab80c035330df122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "806e568556c044deadef68445df1767b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c7f87499104479aa7e362a1a6643ef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad7c8ed877214e468478407d74f351fd",
            "value": "‚Äá440M/440M‚Äá[00:06&lt;00:00,‚Äá110MB/s]"
          }
        },
        "808c4723d90343798a13e4bb43504e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63027f597db43ef921fecb192e86341",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2addf98dbfe6440ea3bd64882dd57426",
            "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá3.16kB/s]"
          }
        },
        "81c7f87499104479aa7e362a1a6643ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc390e10e29440a8008f8e2e6922e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a299f208792e4c4684d5d5546ee18815",
              "IPY_MODEL_4ab2ec8d20e44143a449c303c49ba6ef",
              "IPY_MODEL_a99c28f30d944b6995b3feaa9ff501bd"
            ],
            "layout": "IPY_MODEL_7d7deae95c8b4c7fa0c47d71b0ffa8f8"
          }
        },
        "92b65742e05b4b22adb2a0dd427cf3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70062b3737846d98edef4a5069490b7",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d920ebda24c54d2ea4bc78415e88a46e",
            "value": 440449768
          }
        },
        "95bc6c97d29e4e558f7efccacf8ba8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad6b07320994c1ca5f2d0db0e8ba436",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_02ca9c20647b471796d82c92252a19c7",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "a299f208792e4c4684d5d5546ee18815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0167d1b79d44dceb00190179597dd18",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c107112f6b8e4c19af1ab89fcc9f98d1",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "a99c28f30d944b6995b3feaa9ff501bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe10d084efef4006b4bc349c7c00b9a4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ef701423aa1c46e7bd1c32b8b33ba493",
            "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá2.41MB/s]"
          }
        },
        "ab581f3b41a94744844299f83c80f296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa033a2a14424dbe90111203184fafb8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c4d65fac80234ae68fcc7cb181367c7a",
            "value": "config.json:‚Äá100%"
          }
        },
        "ac9f86d77fe340568102011d7aa1b651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca9f3e1fe62a4c5d97dc4f2dbc24e744",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bb9b8ed3e48d40cf959792bf002bbe44",
            "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá25.3kB/s]"
          }
        },
        "ad7c8ed877214e468478407d74f351fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70062b3737846d98edef4a5069490b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9b8ed3e48d40cf959792bf002bbe44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c107112f6b8e4c19af1ab89fcc9f98d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c157c4df08c0443e89499bf18e6f2159": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4c565fa649147db9e172cd5740c0675",
              "IPY_MODEL_5d828c77f77a4bdeb88ae4f579562bdd",
              "IPY_MODEL_808c4723d90343798a13e4bb43504e0a"
            ],
            "layout": "IPY_MODEL_2eae35b776504ad69bf8600a51c87ff1"
          }
        },
        "c1d1ac64ca834a4697667a534a546c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d65fac80234ae68fcc7cb181367c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca9f3e1fe62a4c5d97dc4f2dbc24e744": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7a9ec7d56349bb8a8d2d5ae1685177": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4c565fa649147db9e172cd5740c0675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9a0f86573e4c5eaa1ef2a80f36a2ca",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7762ad851c2e4f85a8b02d5925d52175",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "d63027f597db43ef921fecb192e86341": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d920ebda24c54d2ea4bc78415e88a46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcabd2bf5f2d45f19e7f49d976f41202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101660bc543e4e4591dd936989261557",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fcc6e8fc93349a4ab80c035330df122",
            "value": 231508
          }
        },
        "e0351f90107c4e2cbe4d5697a4c0706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20cd5f5a94834c2691550d1f2f2c4009",
              "IPY_MODEL_92b65742e05b4b22adb2a0dd427cf3df",
              "IPY_MODEL_806e568556c044deadef68445df1767b"
            ],
            "layout": "IPY_MODEL_3c4a0346c8544aadb10f7d727506ccde"
          }
        },
        "ef701423aa1c46e7bd1c32b8b33ba493": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0167d1b79d44dceb00190179597dd18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa033a2a14424dbe90111203184fafb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad6b07320994c1ca5f2d0db0e8ba436": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe10d084efef4006b4bc349c7c00b9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
